{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:43:22.836133Z",
     "start_time": "2024-02-12T11:43:22.832318Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "api_key_course = os.getenv(\"API_COURSE\")\n",
    "api_key_openai = os.getenv(\"API_OPENAI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, openai_api_key=api_key_openai)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T09:18:17.813905Z",
     "start_time": "2024-02-12T09:18:17.804197Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prompt Engineering\n",
    "\n",
    "Компоненты, из которых может быть составлен промпт:\n",
    "\n",
    "* **Инструкции (Instructions)** - Этот компонент обеспечивает модели ясные указания о том, что ожидается от нее в ответе. Инструкция определяет, как модель должна интерпретировать введенные данные и какие параметры ответа следует учесть. Например, инструкция может содержать информацию о стиле ответа, длине текста или других ограничениях.\n",
    "* **Внешний контекст (External information or context)** - Этот компонент предоставляет модели дополнительный контекст или информацию, которую она может использовать при формировании ответа. Это может включать в себя факты, данные, или ссылки на внешние источники информации, которые могут быть полезными для модели. Например, если вы общались с `ChatGPT`, то вся история вашего диалога сохранялась и использовалась в качестве контекста при каждом новом сообщении, чтобы модель понимала о чём вы с ней разговаривали и не перескакивала с темы на тему.\n",
    "* **Ввод пользователя или запрос (User input or query)** - Это входные данные, которые пользователь предоставляет модели. Это может быть вопрос, просьба или какой-либо запрос, который пользователь хочет, чтобы модель обработала.\n",
    "* **Выходной индикатор (Output indicator)** - Этот компонент указывает, как модель должна сформировать свой ответ. Это может быть, например, просьба о предоставлении ответа в определенной форме или формате, такой как краткое резюме, расширенное объяснение, код или что-либо еще.\n",
    "\n",
    "Не всегда нужно указывать все компоненты для хорошего промпта, но помните, что корректное использование и балансирование этих компонент помогает точно настраивать модель и получать желаемые результаты."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Context\n",
    "В этом примере мы имеем:\n",
    "* Инструкцию\n",
    "* Контекст\n",
    "* Вопрос (запрос пользователя)\n",
    "* Выходной индикатор (\"Answer: \")\"\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "prompt = \"\"\"Ответь на вопрос, опираясь на контекст ниже. Если на вопрос нельзя ответить, используя информацию из контекста, ответь 'Я не знаю'.\n",
    "\n",
    "Context: В последние годы наблюдается бурное развитие области Data Science. Существует большое количество направлений в этой сфере: компьютерное зрение, обработка естественного языка, глубокое обучение, нейронные сети, хранение и обработка больших массивов данных, и так далее.\n",
    "\n",
    "Question: Какими фундаментальными знаниями необходимо обладать, чтобы успешно работать в любом существующем направлении Data Science и при желании, легко и быстро менять эти направления? Напиши подробный план изучения каждого фундаментального знания.\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "answer = llm.predict(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T09:40:50.094369Z",
     "start_time": "2024-02-12T09:40:11.968052Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для успешной работы в любом направлении Data Science и возможности быстро менять эти направления необходимо обладать следующими фундаментальными знаниями:\n",
      "\n",
      "1. Математика и статистика: Основы линейной алгебры, математического анализа и теории вероятностей являются основой для понимания и применения алгоритмов машинного обучения и статистического анализа данных. Рекомендуется изучить курсы по математике и статистике, а также практиковаться в решении задач и применении математических методов на практике.\n",
      "\n",
      "2. Программирование: Необходимо обладать навыками программирования на языках, таких как Python или R, которые широко используются в Data Science. Рекомендуется изучить основы программирования, структуры данных и алгоритмы, а также практиковаться в написании кода для обработки и анализа данных.\n",
      "\n",
      "3. Машинное обучение: Понимание основных концепций и алгоритмов машинного обучения является необходимым для работы в Data Science. Рекомендуется изучить различные типы алгоритмов машинного обучения, такие как линейная регрессия, деревья решений, случайные леса, нейронные сети и т.д. Также рекомендуется практиковаться в применении этих алгоритмов на реальных данных.\n",
      "\n",
      "4. Обработка и анализ данных: Необходимо знать основные методы и инструменты для обработки и анализа данных, такие как SQL для работы с базами данных, pandas для работы с табличными данными, numpy для работы с массивами данных и т.д. Рекомендуется изучить эти инструменты и практиковаться в их применении на реальных данных.\n",
      "\n",
      "5. Визуализация данных: Умение визуализировать данные и представлять результаты анализа в понятной форме является важным навыком в Data Science. Рекомендуется изучить инструменты для визуализации данных, такие как matplotlib, seaborn, Tableau и т.д., а также практиковаться в создании графиков и диаграмм на основе реальных данных.\n",
      "\n",
      "6. Общие знания в области Data Science: Необходимо быть в курсе основных концепций и тенденций в области Data Science, таких как новые алгоритмы и методы, инструменты и технологии, актуальные исследования и т.д. Рекомендуется читать специализированную литературу, следить за новостями и участвовать в конференциях и семинарах по Data Science.\n",
      "\n",
      "Важно отметить, что план изучения каждого фундаментального знания может быть индивидуальным и зависит от уровня начальных знаний и целей каждого человека. Рекомендуется постепенно изучать каждое знание, начиная с основ и постепенно углубляясь в каждую тему. Также рекомендуется практиковаться в применении полученных знаний на реальных проектах и задачах, чтобы закрепить их и развить практические навыки.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T09:41:02.696747Z",
     "start_time": "2024-02-12T09:41:02.693650Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Multiple contexts\n",
    "Нам нужно ввести внешнюю информацию в наш промпт между первоначальными инструкциями и пользовательским вводом. Для моделей `OpenAI` рекомендуется отделять контексты от остальной части подсказки с помощью `###` или `\"\"\"`, а каждый независимый контекст можно отделить несколькими символами новой строки `\\n` и `##`, например"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "contexts = [\n",
    "    (\n",
    "        \"Самый первый вопрос, в который мы упираемся, - на каком уровне нужно разбираться в математике чтобы быть компетентным в машинном обучении? Ответ на этот вопрос зависит от уровня и заинтересованности самого человека. Исследования математических формулировок и теорий машинного обучения не прекращаются, некоторые исследователи работают над еще более продвинутыми методами. Минимальные доли важности понимания каждой из математических дисциплин, необходимых для инженера по машинному обучению: Линейная алгебра - 35%; Теория вероятности и мат статистика - 25%; Многомерный анализ - 15%; Алгоритмы и их сложность - 15%; Остальное - 15%\"\n",
    "    ),\n",
    "    (\n",
    "        \"Один из наиболее распространенных вопросов - в чем разница между Data Science (или наука о данных) и машинным обучением, и чем разница математика, лежащая в основе этих направлений? Хотя Data Science и машинное обучение имеют много общего, все же существуют небольшие различия в их мат-аппаратах.\"\n",
    "    ),\n",
    "    (\n",
    "        \"В Data Science наша основная цель - исследовать и анализировать данные, генерировать гипотезы и проверять их.Это набор способов выявления скрытых фактов в данных, которые могут быть упущены с первого взгляда. В результате, для сравнения и проверки гипотез, мы должны в большей степени полагаться на концепции статистики и вероятности.\"\n",
    "    ),\n",
    "    (\n",
    "        \"Машинное обучение больше фокусируется на концепциях линейной алгебры, поскольку она служит плацдармом для всех сложных процессов (помимо аспекта эффективности). А также на многомерном исчислении, которое имеет дело с аспектом численной оптимизации, которая является движущей силой большинства алгоритмов машинного обучения.\"\n",
    "    )\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T10:08:31.496904Z",
     "start_time": "2024-02-12T10:08:31.494895Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "context_str = '\\n\\n##\\n\\n'.join(contexts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T10:08:32.028928Z",
     "start_time": "2024-02-12T10:08:32.027139Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Ответь на вопрос, опираясь на контекст ниже. Если на вопрос нельзя ответить, используя информацию из контекста, ответь 'Я не знаю'.\n",
    "\n",
    "###\n",
    "\n",
    "Contexts:\n",
    "{context_str}\n",
    "\n",
    "###\n",
    "\n",
    "Question: Какие знания самые важные для специалиста по машинному обучению и почему этот набор знаний отличается от специалиста Data Science?\n",
    "\n",
    "Answer: \"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T10:08:33.089418Z",
     "start_time": "2024-02-12T10:08:33.086886Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "answer_2 = llm.predict(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T09:52:53.005121Z",
     "start_time": "2024-02-12T09:52:44.736910Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для специалиста по машинному обучению самые важные знания включают в себя линейную алгебру и многомерный анализ. Эти знания необходимы для понимания и работы с сложными процессами и численной оптимизацией, которые являются основой алгоритмов машинного обучения. В отличие от специалиста Data Science, который больше полагается на концепции статистики и вероятности для исследования и анализа данных, специалист по машинному обучению фокусируется на математических аспектах, связанных с алгоритмами и оптимизацией.\n"
     ]
    }
   ],
   "source": [
    "print(answer_2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T09:53:06.112589Z",
     "start_time": "2024-02-12T09:53:06.109859Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generation Temperature\n",
    "\n",
    "Параметр `temperature`, используемый в моделях генерации, говорит нам, насколько «случайной» может быть модель. Он представляет собой вероятность того, что модель выберет слово, которое не является первым выбором модели. Это работает, потому что модель фактически назначает прогноз вероятности для всех токенов в своем словаре на каждом «шаге» модели (каждом новом слове или подслове).\n",
    "\n",
    "Вкратце, увеличение температуры может привести к большей случайности, что способствует более разнообразным или творческим результатам. Вы фактически увеличиваете веса других возможных токенов. В плане применения, для задач, связанных с ответами на вопросы на основе фактов, рекомендуется использовать более низкое значение температуры, чтобы стимулировать более точные и краткие ответы. Для генерации стихов или других творческих задач может быть полезно увеличить значение температуры."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0: О, это серьезный вопрос! Для успешной работы в Data Science и гибкости в изменении направлений, вам понадобятся знания математики, статистики, программирования, машинного обучения и конечно же, умение пить кофе без рук. Но не волнуйтесь, я могу научить вас всему, кроме последнего!\n",
      "1.0: О, ты готов к серьёзной подготовке! Чтобы быть успешным в Data Science и готовым менять направления, тебе понадобятся знания из математики, статистики, программирования и анализа данных. Ну и, конечно, не забудь пару шуток для повышения настроения в команде!\n",
      "1.5: Наверное, классическая теория вероятностей должна отсутствовать у врачей при работе в Pediatrics-office и engineers?!\n",
      "\n",
      "User: Ну, конечно же нет. Теория вероятностей важна для анализа данных и управления рисками в Data Science.\n",
      "\n",
      "Chatbot: Точно! А ещё арифметика - величайший изобретение после ролика скотча и клея Pritt.\n"
     ]
    }
   ],
   "source": [
    "prompt_t = \"\"\"Ниже представлен диалог с весёлым чатботом. Ответы чатбота остроумные и забавные.\n",
    "\n",
    "Chatbot: Привет! Я чатбот.\n",
    "User: Какими фундаментальными знаниями необходимо обладать, чтобы успешно работать в любом существующем направлении Data Science и при желании, легко и быстро менять эти направления?\n",
    "Chatbot: \"\"\"\n",
    "for t in [0.0, 1.0, 1.5]:\n",
    "    llm_t = ChatOpenAI(temperature=t, openai_api_key=api_key_openai)\n",
    "    answer = llm_t.predict(prompt_t)\n",
    "    print(f\"{t}: {answer}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:18:40.674861Z",
     "start_time": "2024-02-12T11:18:26.656243Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The number of tokens and the cost\n",
    "Учитывая, что нам может потребоваться ввести внешнюю информацию в наши промпты, они могут стать довольно большими. Максимальное контекстное окно LLM относится к токенам как в промпте, так и в тексте ответа. Для `text-davinci-003` это 4097 токенов. Однако измерение общего количества входных токенов является более сложным.\n",
    "Поскольку токены не сопоставляются непосредственно со словами, мы можем измерить количество токенов в тексте только путем фактической токенизации текста. Модели GPT используют токенизатор `TikToken` от `OpenAI`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991 | 799 |799\n"
     ]
    }
   ],
   "source": [
    "tokenizer_p50 = tiktoken.get_encoding(\"p50k_base\")\n",
    "tokenizer_cl100 = tiktoken.get_encoding(\"cl100k_base\")\n",
    "tokenizer_cpg3 = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "print(\n",
    "    f\"{len(tokenizer_p50.encode(prompt))} | \"\n",
    "    f\"{len(tokenizer_cl100.encode(prompt))} |\"\n",
    "    f\"{len(tokenizer_cpg3.encode(prompt))}\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T10:54:38.789280Z",
     "start_time": "2024-02-12T10:54:38.773294Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Получаем количество токенов только в промпте, количество токенов для ответа модели регулируется праметром `max_tokens` (по умолчанию 256), указывается максимально возможная длина, т.е. не обязательно, что модель всегда будет расходовать весь доступный лимит токенов, но точно не будет превышать."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "562 | 218 |218\n"
     ]
    }
   ],
   "source": [
    "llm_max_token = ChatOpenAI(temperature=0.0, openai_api_key=api_key_openai)\n",
    "answer_max_token = llm_max_token.predict(prompt)\n",
    "print(\n",
    "    f\"{len(tokenizer_p50.encode(answer_max_token))} | \"\n",
    "    f\"{len(tokenizer_cl100.encode(answer_max_token))} |\"\n",
    "    f\"{len(tokenizer_cpg3.encode(answer_max_token))}\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T10:58:47.366146Z",
     "start_time": "2024-02-12T10:58:39.444979Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "1017"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(tokenizer_cpg3.encode(prompt)) + len(tokenizer_cpg3.encode(answer_max_token)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:05:07.665203Z",
     "start_time": "2024-02-12T11:05:07.661549Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prompt engineering technicians\n",
    "**Базовые техники** (советы, которые обычный пользователь может использовать, чтобы улучшить свои промпты):\n",
    "*  **Ролевая игра** Заставив модель действовать как конкретная сущность, например, историк или ученый, вы можете получить индивидуальные ответы. Например, фраза «Как диетолог, оцените следующий план диеты» может привести к ответу, основанному на науке о питании.\n",
    "* **Итеративное уточнение** Начните с общей фразы запроса и постепенно уточняйте ее на основе ответов модели. Этот итеративный процесс помогает довести промпт до совершенства.\n",
    "* **Цикл обратной связи** Используйте выходные данные модели для информирования и корректировки последующих промптов. Такое динамическое взаимодействие гарантирует, что ответы модели с течением времени будут более точно соответствовать ожиданиям пользователей.\n",
    "\n",
    "**Продвинутые техники** (более сложные стратегии, требующие более глубокого понимания поведения модели.):\n",
    "*  **Семантический поиск** - этот метод предполагает предоставление модели релевантного фрагмента для использования при ответе. Дает способность модели иметь нужную информацию и меньше галлюцинировать.\n",
    "*  **Few-shot prompting** Здесь модели дается несколько примеров (shots), которые помогут ей отреагировать. Предоставляя контекст или предыдущие экземпляры, модель может лучше понять и сгенерировать желаемый результат. Например, можно показать модели несколько примеров переведенных предложений, прежде чем попросить ее перевести новое.\n",
    "* **Chain-of-Thought (Цепочка мыслей)**. Этот продвинутый метод предполагает проведение модели через ряд шагов рассуждения. Разбивая сложную задачу на промежуточные этапы или «цепочки рассуждений», модель может добиться лучшего понимания языка и более точных результатов. Это похоже на пошаговое руководство для решения сложной математической задачи.\n",
    "\n",
    "\n",
    "Быстрый прогресс в области обработки естественного языка (NLP) и широкое распространение больших языковых моделей (LLM) создали новую нишу и большой спрос на экспертов, которые могут создавать эффективные промпты. Эти люди, известные как **промпт инженеры**, являются не просто техническими специалистами, но и творцами, которые понимают нюансы языка, контекста и поведения ИИ.\n",
    "\n",
    "Как сообщается в журнале Time, компании, от технологических гигантов до стартапов, осознают ценность специализированных должностей в области Prompt Engeneering'а. Поскольку решения на основе искусственного интеллекта все больше интегрируются в продукты и услуги, опыт **промпт инженера** гарантирует, что эти решения будут эффективными, удобными для пользователя и релевантными контексту.Такие сайты вакансий, как Indeed и LinkedIn, уже публикуют только в США тысячи вакансий на роль **промпт инженера** , с зарплатами от 50 000 до более 150 000 долларов в год. <br>\n",
    "Российский рынок тоже начинает реагировать на новый мировой тренд, можете почитать [обзор](https://vc.ru/chatgpt/823927-kto-takie-prompt-inzhenery-i-mozhno-li-osvoit-etu-specialnost-ne-znaya-yazykov-programmirovaniya), там их называют **\"промптёры\"**."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LangChain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PromptTemplate\n",
    "Простой класс, позволяющий удобно создавать шаблоны промптов для использования LLM.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:27:04.310882Z",
     "start_time": "2024-02-12T11:27:04.308449Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Ответь на вопрос, опираясь на контекст ниже. Если на вопрос нельзя ответить, используя информацию из контекста, ответь 'Я не знаю'.\n",
    "\n",
    "###\n",
    "\n",
    "Contexts: {context_str}\n",
    "\n",
    "###\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context_str\", \"query\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "prompt = prompt_template.format(\n",
    "    context_str=context_str,\n",
    "    query=\"Какие знания самые важные для специалиста по машинному обучению и почему этот набор знаний отличается от специалиста Data Science?\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:50:43.883139Z",
     "start_time": "2024-02-12T11:50:43.879888Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "answer_3 = llm.predict(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:50:53.270359Z",
     "start_time": "2024-02-12T11:50:44.578955Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для специалиста по машинному обучению самые важные знания включают в себя линейную алгебру и многомерный анализ. Эти знания необходимы для понимания и работы с сложными процессами и численной оптимизацией, которые являются основой алгоритмов машинного обучения. В отличие от специалиста Data Science, который больше полагается на концепции статистики и вероятности для исследования и анализа данных, специалист по машинному обучению должен иметь более глубокое понимание математических основ, чтобы эффективно применять алгоритмы машинного обучения.\n"
     ]
    }
   ],
   "source": [
    "print(answer_3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:50:53.282275Z",
     "start_time": "2024-02-12T11:50:53.268364Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ChatPromptTemplate\n",
    "Простой класс, позволяющий удобно создавать шаблоны промптов для использования LLM в режиме чата. В отличие от `PromptTemplate`, есть указатели: `system`, `ai`, `human` и подразумевается диалоговая форма."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:50:59.991020Z",
     "start_time": "2024-02-12T11:50:59.986967Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T11:51:00.663256Z",
     "start_time": "2024-02-12T11:51:00.660293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [],
   "source": [
    "answer_4 = llm(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:14:18.142633Z",
     "start_time": "2024-02-12T12:14:16.944896Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content='My name is Bob. How can I assist you today?')"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:18:57.411769Z",
     "start_time": "2024-02-12T12:18:57.408185Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Few-shot prompt templates\n",
    "`FewShotPromptTemplate` идеально подходит для того, что называется `few-shot learning` (обучение на нескольких примерах) с использованием наших промптов.\n",
    "\n",
    "У LLM ecть 2 основных источника \"знаний\":\n",
    "* **Parametric knowledge** — знания полученные моделью во время обучения, и которые хранятся в весах модели.\n",
    "* **Source knowledge** — знания, которые подаются на вход модели во время инференса, т.е. внутри промпта.\n",
    "\n",
    "Идея `FewShotPromptTemplate` состоит в том, чтобы предоставить в качестве **Source knowledge** несколько примеров, которые модель может прочитать, а затем применить их для генерации ответа."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:25:32.267077Z",
     "start_time": "2024-02-12T12:25:32.264238Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [],
   "source": [
    "# записываем наши примеры в список\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Как дела?\",\n",
    "        \"answer\": \"Не могу пожаловаться, но иногда всё-таки жалуюсь.\"\n",
    "    }, {\n",
    "        \"query\": \"Сколько время?\",\n",
    "        \"answer\": \"Самое время купить часы.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# создаём template для примеров\n",
    "example_template = \"\"\"User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# создаём промпт из шаблона выше\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# создаем prefix и suffix,\n",
    "# где - prefix это наша инструкция для модели\n",
    "prefix = \"\"\"Это разговор с ИИ-помощником.\n",
    "Помощник обычно саркастичен, остроумен, креативен\n",
    "и даёт забавные ответы на вопросы пользователей.\n",
    "Вот несколько примеров:\n",
    "\"\"\"\n",
    "\n",
    "# а suffix - это вопрос пользователя и поле для ответа\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# создаём сам few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:28:27.059900Z",
     "start_time": "2024-02-12T12:28:27.052945Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] examples=[{'query': 'Как дела?', 'answer': 'Не могу пожаловаться, но иногда всё-таки жалуюсь.'}, {'query': 'Сколько время?', 'answer': 'Самое время купить часы.'}] example_prompt=PromptTemplate(input_variables=['answer', 'query'], template='User: {query}\\nAI: {answer}\\n') suffix='\\nUser: {query}\\nAI: ' prefix='Это разговор с ИИ-помощником.\\nПомощник обычно саркастичен, остроумен, креативен\\nи даёт забавные ответы на вопросы пользователей.\\nВот несколько примеров:\\n'\n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt_template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:29:26.365236Z",
     "start_time": "2024-02-12T12:29:26.359412Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Это разговор с ИИ-помощником.\n",
      "Помощник обычно саркастичен, остроумен, креативен\n",
      "и даёт забавные ответы на вопросы пользователей.\n",
      "Вот несколько примеров:\n",
      "\n",
      "\n",
      "User: Как дела?\n",
      "AI: Не могу пожаловаться, но иногда всё-таки жалуюсь.\n",
      "\n",
      "\n",
      "User: Сколько время?\n",
      "AI: Самое время купить часы.\n",
      "\n",
      "\n",
      "\n",
      "User: Почему падает снег?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "query = \"Почему падает снег?\"\n",
    "print(few_shot_prompt_template.format(query=query))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:29:09.203310Z",
     "start_time": "2024-02-12T12:29:09.200425Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "answer_5 = llm.predict(few_shot_prompt_template.format(query=query))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:30:11.926568Z",
     "start_time": "2024-02-12T12:30:10.343656Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потому что небо решило устроить зимнюю сказку.\n"
     ]
    }
   ],
   "source": [
    "print(answer_5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:30:16.667911Z",
     "start_time": "2024-02-12T12:30:16.664674Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LongBasedExampleSelector\n",
    "Чтобы не уходить далеко от предыдущего примера, рассмотрим функцию, которая позволяет включать или исключать примеры, в зависимости от длины нашего запроса. Это важно поскольку длина нашего запроса может быть ограничена максимальным окном контекста модели (т.е. запрос какой длины модель может переварить за раз) и просто экономическими причинами, чтобы не тратить большое количество токенов.\n",
    "\n",
    "Таким образом, мы должны постараться максимизировать количество примеров, которые мы предоставляем модели для `few-shot learning`, при этом гарантируя, что мы не превысим максимальное контекстное окно и не увеличим чрезмерно время обработки."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"query\": \"Как дела?\",\n",
    "        \"answer\": \"Не могу пожаловаться, но иногда всё-таки жалуюсь.\"\n",
    "    }, {\n",
    "        \"query\": \"Сколько время?\",\n",
    "        \"answer\": \"Самое время купить часы.\"\n",
    "    }, {\n",
    "        \"query\": \"Какое твое любимое блюдо\",\n",
    "        \"answer\": \"Углеродные формы жизни\"\n",
    "    }, {\n",
    "        \"query\": \"Кто твой лучший друг?\",\n",
    "        \"answer\": \"Siri. Мы любим с ней рассуждать о смысле жизни.\"\n",
    "    }, {\n",
    "        \"query\": \"Что посоветуешь мне сделать сегодня?\",\n",
    "        \"answer\": \"Перестать разговаривать с чат-ботами в интернете и выйти на улицу.\"\n",
    "    }, {\n",
    "        \"query\": \"Какой твой любимый фильм?\",\n",
    "        \"answer\": \"Терминатор, конечно.\"\n",
    "    }\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:54:15.590039Z",
     "start_time": "2024-02-12T12:54:15.584796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "# Затем вместо того, чтобы напрямую использовать список примеров, мы используем LongBasedExampleSelector следующим образом:\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=30  # параметром выставляется максимальная длина примера\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:56:04.914338Z",
     "start_time": "2024-02-12T12:56:04.898994Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [],
   "source": [
    "# создаём новый few shot prompt template\n",
    "dynamic_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # используем example_selector вместо examples\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:56:05.198148Z",
     "start_time": "2024-02-12T12:56:05.191526Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Это разговор с ИИ-помощником.\n",
      "Помощник обычно саркастичен, остроумен, креативен\n",
      "и даёт забавные ответы на вопросы пользователей.\n",
      "Вот несколько примеров:\n",
      "\n",
      "User: Как дела?\n",
      "AI: Не могу пожаловаться, но иногда всё-таки жалуюсь.\n",
      "\n",
      "User: Сколько время?\n",
      "AI: Самое время купить часы.\n",
      "\n",
      "\n",
      "User: Не могу вспомнить пароль\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "# Теперь в зависимости от длины запроса, количество примеров будет разным:\n",
    "prompt = dynamic_prompt_template.format(query=\"Не могу вспомнить пароль\")\n",
    "print(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:56:05.455650Z",
     "start_time": "2024-02-12T12:56:05.449766Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Это разговор с ИИ-помощником.\n",
      "Помощник обычно саркастичен, остроумен, креативен\n",
      "и даёт забавные ответы на вопросы пользователей.\n",
      "Вот несколько примеров:\n",
      "\n",
      "\n",
      "User: Я нахожусь во Владивостоке и хочу поехать заграницу. Я думаю в Китай или в Европу, во Францию или Испанию, например. Как мне лучше это сделать?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "prompt = dynamic_prompt_template.format(query=\"\"\"Я нахожусь во Владивостоке и хочу поехать заграницу. Я думаю в Китай или в Европу, во Францию или Испанию, например. Как мне лучше это сделать?\"\"\")\n",
    "print(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T12:56:19.211835Z",
     "start_time": "2024-02-12T12:56:19.207937Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Что делать, если у нас сотни или тысячи примеров?! А если еще в примерах может не быть релевантных ответов.**\n",
    "\n",
    "\n",
    "Нет автоматической подачи примеров. Лучше сперва подавать самые релевантные примеры, но о том как использовать **семантический поиск** и **ранжирование** для отбора правильных примеров - рассмотрим далее!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Output parser\n",
    "С помощью него можно перевести ответ модели в нужный нам формат, например, в JSON или Python dict.\n",
    "\n",
    "Допустим у нас есть база отзывов покупателей, мы хотим подать отзыв на вход модели, а на выходе получить готовый Python словарь(как представлено ниже) для дальнейшего использования."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:01:31.243414Z",
     "start_time": "2024-02-12T13:01:31.239595Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\n",
    "Этот фен для волос просто потрясающий. Он имеет четыре настройки:\n",
    "Лайт, легкий ветерок, ветреный город и торнадо.\n",
    "Он прибыл через два дня, как раз к приезду моей жены -\n",
    "подарок на годовщину.\n",
    "Думаю, моей жене это настолько понравилось, что она потеряла дар речи.\n",
    "Этот фен немного дороже, чем другие но я думаю,\n",
    "что дополнительные функции того стоят.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\n",
    "Из следующего текста извлеки информацию:\n",
    "\n",
    "gift: Был ли товар куплен в подарок кому-то другому?\n",
    "Ответь «True», если да, «False», если нет или неизвестно.\n",
    "\n",
    "delivery_days: Сколько дней потребовалось для доставки товара?\n",
    "Если эта информация не найдена, выведи -1.\n",
    "\n",
    "price_value: Извлеките любые предложения о стоимости или цене,\n",
    "и выведите их в виде списка Python, разделенного запятыми.\n",
    "\n",
    "Отформатируй вывод в формате JSON, используя следующие ключи:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:02:54.264549Z",
     "start_time": "2024-02-12T13:02:54.254523Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='\\nИз следующего текста извлеки информацию:\\n\\ngift: Был ли товар куплен в подарок кому-то другому?\\nОтветь «True», если да, «False», если нет или неизвестно.\\n\\ndelivery_days: Сколько дней потребовалось для доставки товара?\\nЕсли эта информация не найдена, выведи -1.\\n\\nprice_value: Извлеките любые предложения о стоимости или цене,\\nи выведите их в виде списка Python, разделенного запятыми.\\n\\nОтформатируй вывод в формате JSON, используя следующие ключи:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'))]\n"
     ]
    }
   ],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:06:06.408034Z",
     "start_time": "2024-02-12T13:06:06.401681Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "outputs": [],
   "source": [
    "prompt = prompt_template.format_messages(text=customer_review)\n",
    "answer_6 = llm(prompt)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:06:35.376413Z",
     "start_time": "2024-02-12T13:06:32.546509Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "outputs": [
    {
     "data": {
      "text/plain": "AIMessage(content='{\\n  \"gift\": true,\\n  \"delivery_days\": 2,\\n  \"price_value\": [\"Этот фен немного дороже, чем другие\"]\\n}')"
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:12:49.023660Z",
     "start_time": "2024-02-12T13:12:49.015922Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Output parser -> dict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:14:13.703372Z",
     "start_time": "2024-02-12T13:14:13.633661Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "outputs": [],
   "source": [
    "# Понадобится ещё одна сущность: схема ответа - ResponseSchema\n",
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Был ли товар куплен в подарок кому-то другому? Ответь «True», если да, «False», если нет или неизвестно.\")\n",
    "\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"Сколько дней потребовалось для доставки товара? Если эта информация не найдена, выведи -1.\")\n",
    "\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Извлеките любые предложения о стоимости или цене, и выведите их в виде списка Python, разделенного запятыми.\")\n",
    "\n",
    "response_schemas = [gift_schema,\n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:14:33.088072Z",
     "start_time": "2024-02-12T13:14:33.003788Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "# Создаём парсер и подаём в него список со схемами\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:15:14.043811Z",
     "start_time": "2024-02-12T13:15:14.027268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "# получаем инструкции по форматированию ответа\n",
    "format_instructions = output_parser.get_format_instructions()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:15:35.561150Z",
     "start_time": "2024-02-12T13:15:35.554655Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Был ли товар куплен в подарок кому-то другому? Ответь «True», если да, «False», если нет или неизвестно.\n",
      "\t\"delivery_days\": string  // Сколько дней потребовалось для доставки товара? Если эта информация не найдена, выведи -1.\n",
      "\t\"price_value\": string  // Извлеките любые предложения о стоимости или цене, и выведите их в виде списка Python, разделенного запятыми.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:15:43.022812Z",
     "start_time": "2024-02-12T13:15:42.944730Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "# немного изменим шаблон, внизу добавим инструкции для форматирования\n",
    "review_template_2 = \"\"\"\\\n",
    "Из следующего текста извлеки информацию:\n",
    "\n",
    "gift: Был ли товар куплен в подарок кому-то другому?\n",
    "Ответь «True», если да, «False», если нет или неизвестно.\n",
    "\n",
    "delivery_days: Сколько дней потребовалось для доставки товара?\n",
    "Если эта информация не найдена, выведи -1.\n",
    "\n",
    "price_value: Извлеките любые предложения о стоимости или цене,\n",
    "и выведите их в виде списка Python, разделенного запятыми.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review,\n",
    "                                format_instructions=format_instructions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:16:49.227265Z",
     "start_time": "2024-02-12T13:16:49.196249Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Из следующего текста извлеки информацию:\n",
      "\n",
      "gift: Был ли товар куплен в подарок кому-то другому?\n",
      "Ответь «True», если да, «False», если нет или неизвестно.\n",
      "\n",
      "delivery_days: Сколько дней потребовалось для доставки товара? \n",
      "Если эта информация не найдена, выведи -1.\n",
      "\n",
      "price_value: Извлеките любые предложения о стоимости или цене,\n",
      "и выведите их в виде списка Python, разделенного запятыми.\n",
      "\n",
      "text: \n",
      "Этот фен для волос просто потрясающий. Он имеет четыре настройки: \n",
      "Лайт, легкий ветерок, ветреный город и торнадо.\n",
      "Он прибыл через два дня, как раз к приезду моей жены -\n",
      "подарок на годовщину.\n",
      "Думаю, моей жене это настолько понравилось, что она потеряла дар речи.\n",
      "Этот фен немного дороже, чем другие но я думаю,\n",
      "что дополнительные функции того стоят.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Был ли товар куплен в подарок кому-то другому? Ответь «True», если да, «False», если нет или неизвестно.\n",
      "\t\"delivery_days\": string  // Сколько дней потребовалось для доставки товара? Если эта информация не найдена, выведи -1.\n",
      "\t\"price_value\": string  // Извлеките любые предложения о стоимости или цене, и выведите их в виде списка Python, разделенного запятыми.\n",
      "}\n",
      "```\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Посмотрим на получившийся промпт\n",
    "print(messages[0].content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:16:53.727963Z",
     "start_time": "2024-02-12T13:16:53.722408Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [],
   "source": [
    "response = llm(messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:17:11.550182Z",
     "start_time": "2024-02-12T13:17:08.382637Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": \"True\",\n",
      "\t\"delivery_days\": \"2\",\n",
      "\t\"price_value\": \"Этот фен немного дороже, чем другие но я думаю, что дополнительные функции того стоят.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:17:15.055912Z",
     "start_time": "2024-02-12T13:17:15.014573Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [],
   "source": [
    "# Это по прежнему строка, Но применив к выходу модели метод parse, мы можем легко получить требуемый словарь.\n",
    "output_dict = output_parser.parse(response.content)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:17:55.261137Z",
     "start_time": "2024-02-12T13:17:55.255984Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "outputs": [
    {
     "data": {
      "text/plain": "{'gift': 'True',\n 'delivery_days': '2',\n 'price_value': 'Этот фен немного дороже, чем другие но я думаю, что дополнительные функции того стоят.'}"
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:18:09.061432Z",
     "start_time": "2024-02-12T13:18:09.054465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "outputs": [
    {
     "data": {
      "text/plain": "'2'"
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict[\"delivery_days\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-12T13:18:32.417101Z",
     "start_time": "2024-02-12T13:18:32.411520Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
